---
title: 透過 Kafka & Golang 設計一套資料同步組件 
date: 2020-04-19 20:25:03
tags:
- golang
- kafka
- mysql
categories:
- 專案分享
---

# 前言

本篇將透過幾個面向來簡要介紹如何規劃一套資料自動同步系統：

1. 專案情境

2. 專案介紹
    - 專案目標
    - 系統架構
    - 時序圖
    - 專案瓶頸與突破
    - 專案成果

<!--more-->

# 情境與思維

## 專案情境

隨著業務的穩定發展，資料量級必定也是呈現指數般的成長，其中常遇到的問題是：

1. 單一資料如何做更多元的應用，發揮資料更大的價值
隨著業務的發展，資料庫不單單只是記錄交易而已，更多的應用也會應運而生，比如報表系統、對帳系統、風控系統、分析系統等等。
為了滿足這些不同業務，就必須對資料做更多不同層面的應用、剖析與計算，但是這些操作並非都是原資料庫所擅長的，因此要規劃一個可接受的方案去滿足業務變化與需求。
ps: 其中這裡提到的“可接受”更可以明確定義是否滿足以下要求：
	- 資料即時性的要求：同步速度不能太慢，要在可接受延遲時間內到達。
	- 資料一致性的要求：同步結果需要與原資料庫一致，不因同步過程而產生不同結果。
	- 資料可靠性的要求：同步過程必須可靠，不能遺失資料。

2. 如何降低原資料庫的壓力
如上所述，隨著業務的發展，資料庫也會負責更多不同類型的事務，因此若這些業務都在原資料庫上處理的話，必定對核心業務造成影響，因此便有可能考慮用其他類型的資料庫來處理原資料庫不擅長之部分，但是一但決定採取這個方案，便要考量的便是如何將資料從原資料庫同步到新資料庫，具體來說要考量以下問題：
	- 以何種方式同步：畢竟非同原的數據庫未必支持數據間的同步。
	- 如何降低同步帶來的影響：比如用排程定期查詢資料庫就不是個好方法。
	- 如何提高資料的複用：如何將同步資料提供給多個資料庫使用。

3. 多來源庫的問題
有時我們會以各種維度去區分資料庫，比如以業務來區分資料庫，因而導致原資料庫有多台的情況，雖然這某一層面或多或少分擔資料庫的壓力，但是也會對於業務應用方面帶來些許不便，舉例來說如果要規劃一個風控系統，必定不會只考量單一種業務庫。
除了應用層面外，在管理方面也會帶來一些不便，具體會體現在幾個面向：
	- 跨區問題：GCP & AWS 都有所謂的服務區，比如你的機器可以架在 Tokyo，也可以架在 Korea，但是不同區域會帶來一些問題，比如網路通信的差異。
	- 防火牆議題：需要制定更多相關規則來滿足業務。
	- 設定檔問題：應用服務可能需要設定多個來源庫的連線設定。


## 專案思維

考量上述場景，專案的思維如下：

1. 以 replicate 方式同步：
我們透過 MySQL 原有的 replicate 協議來同步資料，與 MySQL 建立起 Master/Slave，以獲取每一筆資料的變動。

2. 以 mysqldump 做初始化：
在啟動同步的初期，我們會先針對現有資料庫做一次初始化，獲取當前數據庫的所有資料，透過這個方法，我們唯一的風險僅在 mysqldump 執行剛開始會先 flush tables，後續便會不斷地將目前的資料已快照的方式傳遞給你

3. 使用 Kafka 傳遞資料：
使用 Kafka 主要是考量其幾個特性，這邊我們先簡略說明，待後續會有 Kafka 系列的相關文章再跟大家做詳細的分享：
	- 水平擴展方便：讓我們可以隨著業務量來應變
	- 訊息傳遞量與速度：Kafka 在訊息傳遞速度上，無論訊息大小為何，相較於其他 MQ 都有極大的優勢
	- 可容錯性高：可容錯性高這點不單指的是 Kafka brokers 本身，對於 client 端也十分容易實現，這全仰賴於 Kafka 本身 Topic 的 Partition 和 Replication 的搭配
	- 可輕鬆實現訊息傳遞的 at least once，讓我們對於消息傳遞有一定的可靠性


# 專案簡介

## 專案目標 

- 提供資料全量和增量備份
- 保證資料的最終一致性
- 保證資料一定至少推送一次 (at least once)
- 保證與資料來源的連線品質，透過檢測心跳自動切換連線（僅限同一 MySQL 集群）
- 保證高併發的有序性
- 保證資料同步的即時性

## 系統架構

![Framework](./framework.png)


## 時序圖

![Flow](./flow_zh.png)

- SourceMySQL: 原資料所在的 MySQL 集群，此為同步資料的來源
- DSS: Ditto Synchronize Service，負責資料同步、解析以及推送
- MongoDB: 負責儲存解析後的資料，供日後校驗資料使用
- DWS: Ditto Worker Service，負責資料驗證、心跳檢測以及資料補正等等
- Kafka: 提供 Application Tier 訂閱資料
- MySQL: 負責儲存服務狀態以及失敗的事件
- DCS: Ditto Cache Service 負責暫存一段時間的處理事件與服務狀態
- Event: 解析後的資料
- Offset: 同步時產生的log


## 專案瓶頸與突破 

### 連線品質的保證

### 全量備份的方案選擇

### 增量備份的效能優化 

### 全量備份的效能優化

### 高併發的有序性

### 資料可靠的保證


## 專案成果
- 單一資料庫同步速率為 5000 rows/sec
-  

