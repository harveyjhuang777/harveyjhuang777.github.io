---
title: 透過 Kafka & Golang 設計一套數據同步系統 
date: 2020-04-19 20:25:03
tags:
- golang
- kafka
- mysql
categories:
- 那些年一起踩過的坑
---

# 前言

本篇將透過幾個面向來簡要介紹如何規劃一套數據同步系統：

1. 專案情境

2. 專案介紹
    - 專案目標
    - 系統架構
    - 時序圖
    - 專案瓶頸與突破
    - 專案成果

<!--more-->

# 情境與思維

## 專案情境

隨著業務的穩定發展，資料量級必定也是呈現指數般的成長，其中常遇到的問題是：

1. 單一資料如何做更**多元的應用**，發揮資料更大的價值
隨著業務的發展，資料庫不單單只是記錄交易而已，更多的應用也會應運而生，比如報表系統、對帳系統、風控系統、分析系統等等，因此為了滿足這些不同業務，就必須對資料做更多不同層面的應用、剖析與計算，但是這些操作並非都是原資料庫所擅長的，因此要規劃一個可接受的方案去滿足業務變化與需求。
ps: 其中這裡提到的“可接受”更可以明確定義是否滿足以下要求：
	- 資料**即時性**的要求：同步速度不能太慢，要在可接受延遲時間內到達。
	- 資料**一致性**的要求：同步結果需要與原資料庫一致，不因同步過程而產生不同結果。
	- 資料**可靠性**的要求：同步過程必須可靠，不能遺失資料。

2. 如何**降低原資料庫的壓力**
如上所述，隨著業務的發展，資料庫也會負責更多不同類型的事務，因此若這些業務都在原資料庫上處理的話，必定對核心業務造成影響，因此便有可能考慮用其他類型的資料庫來處理原資料庫不擅長之部分，但是一但決定採取這個方案，便要考量的便是如何將資料從原資料庫同步到新資料庫，具體來說要考量以下問題：
	- 以何種方式同步：畢竟非同原的數據庫未必支持數據間的同步。
	- 如何降低同步帶來的影響：比如用排程定期查詢資料庫就不是個好方法。
	- 如何提高資料的複用：如何將同步資料提供給多個資料庫使用。

3. **多來源庫的問題**
有時我們會以各種維度去區分資料庫，比如以業務來區分資料庫，因而導致原資料庫有多台的情況，雖然這某一層面或多或少分擔資料庫的壓力，但是也會對於業務應用方面帶來些許不便，舉例來說如果要規劃一個風控系統，必定不會只考量單一種業務庫。
除了應用層面外，在管理方面也會帶來一些不便，具體會體現在幾個面向：
	- 跨區問題：GCP & AWS 都有所謂的服務區，比如你的機器可以架在 Tokyo，也可以架在 Korea，但是不同區域會帶來一些問題，比如網路通信的差異。
	- 防火牆議題：需要制定更多相關規則來滿足業務。
	- 設定檔問題：應用服務可能需要設定多個來源庫的連線設定。


## 技術選型

考量上述場景，專案的思維如下：

1. **以 replicate 方式同步**：
我們透過 MySQL 原有的 replicate 協議來同步資料，與 MySQL 建立起 Master/Slave，以獲取每一筆資料的變動。

2. **以 mysqldump 做初始化**：
在啟動同步的初期，我們會先針對現有資料庫做一次初始化，獲取當前數據庫的所有資料，透過這個方法，我們唯一的風險僅在 mysqldump 執行剛開始會先 flush tables，後續便會不斷地將目前的資料已快照的方式傳遞給你

3. **使用 Kafka 傳遞資料**：
使用 Kafka 主要是考量其幾個特性，這邊我們先簡略說明，待後續會有 Kafka 系列的相關文章再跟大家做詳細的分享：
	- **水平擴展方便**：讓我們可以隨著業務量來應變
	- **訊息傳遞量與速度**：Kafka 在訊息傳遞速度上，無論訊息大小為何，相較於其他 MQ 都有極大的優勢
	- **可容錯性高**：可容錯性高這點不單指的是 Kafka brokers 本身，對於 client 端也十分容易實現，這全仰賴於 Kafka 本身 Topic 的 Partition 和 Replication 的搭配
	- 可輕鬆實現訊息傳遞的 **at least once**，讓我們對於消息傳遞有一定的可靠性


# 專案簡介

## 專案目標 

根據專案情境以及系統的通用性，我們將專案目標定義為以下幾點：

- 提供資料全量和增量備份
- 保證資料的最終一致性
- 保證資料一定至少推送一次 (at least once)
- 保證與資料來源的連線品質，透過檢測心跳自動切換連線（僅限同一 MySQL 集群）
- 保證高併發的有序性
- 保證資料同步的即時性
- 服務本身是無狀態，方便水平擴展

## 設計思路 

### 核心概念
根據上述的目標可以發現，這套系統主要是基於 at least once 的前提下來設計，這便代表：
1. 資料會有重複丟的現象(只會出現在補救資料的場景)
2. 下游必須做好冪等性

至於這樣處理的好處在於：
1. 延遲性更低，因為可以把一些驗證擺在後續做，若有問題再回補。
2. 資料一致性和冪等性就以唯一識別碼處理

此外這套系統也仰賴 Kafka 的特性，具體來說：
1. 高吞吐量
2. cluster & replicate 保證可靠
3. partition 保證併發的有序性

因此我們的設計便能在確保吞吐量的同時，也保證資料一致性跟可靠性

### 運作流程

![Flow](./flow_zh.png)

- 同步組件:
    - 同步模組: 負責與來源庫建立協議獲取事件通知並將其解析後，推送到 MQ 。
    - 排程模組: 負責在背景定時執行任務，包括確認連線品質、確認數據落地以及紀錄同步品質與處理進度。
    - 快取模組: 負責暫存資訊，以便背景服務後續處理。
    - 告警模組: 負責在服務異常時，針對連線異常、數據同步異常來告警。
- 來源庫: 數據同步的來源資料庫，這邊特別指 MySQL。
- 備份庫: 儲存以解析的數據，以便在排成偵測到數據同步異常時能有資料補救。
- 設定庫: 負責紀錄失敗事件，以及記錄數據同步的進度。
- MQ: 負責讓同步組件推送解析數據，同時也讓使用者能訂閱事件。 
- 使用者: 需要同步數據的服務。

#### 同步流程

一開始紀錄 MySQL 的 GTID 後，向 MySQL 分別申請 replicate 和 mysqldump 兩種協議，將數據流分為全量同步和增量同步兩個部分同時進行，這麼做主要有以下優點：
1. 全量同步和增量同步的資料流可以完全分開，更易於 debug ，原因是全量同步得到的是完整資料，增量同步得到的是變動資訊。
2. 可以針對全量同步和增量同步做更佳的效能優化，比如全量同步的資料是完整的，因此可以併發去做事件解析，然而增量同步就要考量資料的順序性來做優化。
3. 下游服務可以自己決定是否要全量備份的資料

#### 背景服務

1. 儲存服務的處理進度點：
服務會定期紀錄目前數據同步的進度，更準確的說我們紀錄該組 MySQL 的 gtid 資訊，這主要是為了在服務重啟時能夠以剛才的進度繼續執行同步。

2. 紀錄服務的監控數據：
紀錄的數據包括同步速率、連線品質等等。

3. 監控告警：
針對異常監控發出告警到 slack 或下游應用服務。

4. 驗證資料落地：
透過事後驗證的方式，我們將資料驗證落地與補救機制放在後面去做，原因有：
    - 同步數據時不用等待數據落地，加速同步進行。
    - 數據不落地的比例十分低，因此只要事後根據失敗時間點資料回補就行了。


## 專案瓶頸與突破 

終於要來跟大家分享**那些年一起踩過的坑**了，下面我將針對實作專案時，所遇到的難題跟大家一一介紹。

### 連線品質的保證
一開始便有考量到連線品質的把控，因此一開始的做法是如同 MySQL Master/Slave 一樣，服務也去監聽 heartbeat 表確保連線品質。
殊不知忽略一個顯而易見的盲點，如果同步中斷...就獲取不到 heartbeat 表的 binlog 事件 Orz。
幸好這個問題易於解決，只需要定期也檢測最新一次收到事件的時間點就可以了。

### 全量同步的方案選擇
由於同步數據必定有初始化的需求，也就是這裡提到的全量備份，當時心中跑出三種方案：
1. 透過程式端拉sql：
不採用！原因如下：
    - 對資料庫造成一定負擔。
    - 無法確認同步位置，比如要從哪個 GTID 位置開始。
    - 無法適用全部情況，因為每個 table schema 都不一樣。

2. 拷貝文件後在本地解析：
不採用！原因如下：
    - 需要人工介入的部分，比如 DBA。
    - 場景並非 MySQL to MySQL。

3. mysqldump：
採用！原因如下：
    - 可以從程式碼擷取訊息解析。
    - 能夠確認同步的起始位置。
    - 適用多數狀況。

### 增量同步的效能優化
由於增量同步得到的是變動資訊，因此考量數據的一致性便沒有做併發，但事後發現實在太慢拉!
因此為了達到在高併發的情況下也能保證資料最終一致性，做了以下優化:
    - 在解析事件時，也將事件的 Primary Key 做為 Kafka 傳遞訊息的 Message Key。
    - 透過 Kafka 的 Partition 特性，在傳遞訊息時以 Message Key 分發訊息到不同 Partition。
至於為什麼這樣便可以達到分區的有序性呢？
舉個例子，假設今天你的訂單的 Primary Key 是訂單編號，如此你便可以確保同一個編號的變動必定落在同一個 Partition，也就是代表隊單筆訂單而言，你的最終結果是不變的！
ref: [How Apache Kafka messages are written](https://docs.datastax.com/en/kafka/doc/kafka/kafkaHowMessages.html)
![Key](./key.png)

### 全量同步的效能優化

全量同步的效能優化部分，當時也想了兩個方案去實作：
1. 依照 table 數目以 goroutine 去執行 mysqldump，比如有三張表就開三個 goroutine 去執行 mysqldump:
失敗！原因在於 mysqldump 會有執行 flush tables with read lock ，多個 mysqldump 就等同於短時間會有多次執行，進而阻塞後續後續其他線程的寫操作。
原因是因為首先執行的 mysqldump 會開始 query 資料，也就是執行類似以下的語句

``` sql
SELECT * FROM `example`.`order`
```

緊接著下一個 mysqldump 執行到 flush tables with read lock 時，便有可能因為上述語句查詢較久而在等待鎖釋放，因此後面線程便要等待 flush tables with read lock 的執行，此時執行 

``` sql
show processlist 
```

便看到的便是一堆操作等待著 flush tables with read lock 執行。

2. mysqldump 執行一次，將接到 raw event 丟到 channel 裡面，透過 worker pool 去做執行：
採用！原因在於經過 pprof 我們發現執行慢的並不是 mysqldump 資料倒不夠快，而是解析事件需要較長的時間。
由於 mysqldump 都是完整資料，因此我們採用 worker pool 批次解析事件，藉此加快處理速度，最終我們在全量同步的效能優化部分得到 50 倍的提升。

### 資料可靠的保證

我們主要是透過以下幾個設計滿足訊息的可靠性：
1. Kafka replicate：
可以透過 replicate & min.insync.replicas 的設定搭配，使得 Kafka 在滿足可靠性的要求後才會回覆 Producer 成功。
比如 replicate = 3 & min.insync.replicas = 2，Kafka 只有在確認到有兩個 replicate 落地後才會回覆訊息接收成功

2. producer ack & retry：
Kafka 的 producer 傳送訊息給 Kafka 可以決定是否要等待 Kafka brokers 回應，以及擁有 retry 機制。
因此搭配 replicate 機制，我們就可以確保每份訊息至少都有一個副本存在，如此便可以確保此系統具有較高的可靠性。


# 結論
- 單一資料庫同步速率約 5000-8000 rows/sec
- 記憶體使用量約 500 mb
